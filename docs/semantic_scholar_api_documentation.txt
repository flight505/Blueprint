================================================================================
SEMANTIC SCHOLAR API DOCUMENTATION
LLM-Optimized Reference for Academic Paper & Citation Services
================================================================================

DOCUMENT METADATA
-----------------
Version: 1.0
Last Updated: January 2025
Primary Source: Semantic Scholar API (api.semanticscholar.org)
Coverage: Academic Graph API, Recommendations API, Datasets API
External ID Support: DOI, CrossRef, PubMed, arXiv, ACL, MAG, PMCID, CorpusID

================================================================================
SECTION 1: OVERVIEW AND ARCHITECTURE
================================================================================

1.1 WHAT IS SEMANTIC SCHOLAR?
-----------------------------
Semantic Scholar is a free, AI-powered academic search engine developed by the
Allen Institute for AI (Ai2). It indexes over 200 million scholarly papers
across all disciplines and provides programmatic access through REST APIs.

1.2 API SERVICES ARCHITECTURE
-----------------------------
Three primary API services with distinct base URLs:

SERVICE             BASE URL                                        PURPOSE
--------------------------------------------------------------------------------
Academic Graph      https://api.semanticscholar.org/graph/v1        Papers, authors, citations
Recommendations     https://api.semanticscholar.org/recommendations/v1  Paper recommendations
Datasets            https://api.semanticscholar.org/datasets/v1     Bulk data downloads

1.3 RESPONSE FORMAT
-------------------
All APIs return JSON format responses.

================================================================================
SECTION 2: AUTHENTICATION AND ACCESS
================================================================================

2.1 API KEY ACQUISITION
-----------------------
URL: https://www.semanticscholar.org/product/api#api-key-form

IMPORTANT RESTRICTIONS (as of November 2024):
- API keys from free email domains (gmail, yahoo, etc.) NO LONGER accepted
- Third-party app key requests NO LONGER approved
- Inactive keys (60+ days) are automatically pruned
- New key requests backlogged ~1 month

2.2 RATE LIMITS
---------------
UNAUTHENTICATED:
- Shared pool: 5,000 requests per 5 minutes (among ALL unauthenticated users)
- Effective rate: ~17 requests/second shared

AUTHENTICATED (API Key):
- Default: 1 request per second (RPS) across all endpoints
- Batch endpoints (/paper/batch, /paper/search, /recommendations): 1 RPS
- Single-item endpoints: 10 RPS (some cases)

2.3 AUTHENTICATION HEADER
-------------------------
Header Name: x-api-key
Header Value: <your_api_key>

Example:
```
headers = {"x-api-key": "your_api_key_here"}
```

================================================================================
SECTION 3: EXTERNAL IDENTIFIER SUPPORT (CrossRef, DOI, PubMed, etc.)
================================================================================

3.1 SUPPORTED EXTERNAL ID FORMATS
---------------------------------
Semantic Scholar supports lookup by multiple external identifier systems:

IDENTIFIER      PREFIX FORMAT           EXAMPLE
--------------------------------------------------------------------------------
S2 Paper ID     (none - direct use)     649def34f8be52c8b66281af98ae884c09aef38b
S2 Corpus ID    CorpusID:               CorpusID:37220927
DOI             DOI: or direct          DOI:10.1038/nrn3241 or 10.1038/nrn3241
arXiv           ARXIV: or arXiv:        ARXIV:2106.15928 or arXiv:0711.0914
PubMed          PMID:                   PMID:19872477
PubMed Central  PMCID:                  PMCID:PMC2323456
ACL Anthology   ACL:                    ACL:W12-3903
MAG (Microsoft) MAG:                    MAG:2950000001
URL             URL:                    URL:https://semanticscholar.org/paper/...

3.2 CROSSREF INTEGRATION
------------------------
CrossRef DOIs work directly with Semantic Scholar APIs:

LOOKUP BY DOI:
```python
# Direct DOI lookup
paper = requests.get(
    "https://api.semanticscholar.org/graph/v1/paper/10.1038/nrn3241",
    params={"fields": "title,authors,year,citationCount"}
)

# With DOI prefix
paper = requests.get(
    "https://api.semanticscholar.org/graph/v1/paper/DOI:10.1038/nrn3241",
    params={"fields": "title,authors,year,citationCount"}
)
```

BATCH LOOKUP BY MULTIPLE DOIs:
```python
response = requests.post(
    "https://api.semanticscholar.org/graph/v1/paper/batch",
    headers={"x-api-key": api_key},
    params={"fields": "title,authors,year,externalIds"},
    json={"ids": [
        "10.1038/nrn3241",
        "DOI:10.1093/nar/gkr1047",
        "PMID:19872477",
        "arXiv:2106.15928"
    ]}
)
```

3.3 EXTERNAL IDS FIELD IN RESPONSES
-----------------------------------
Request externalIds field to get all associated identifiers:

```python
params = {"fields": "externalIds,title"}
```

Response structure:
```json
{
  "paperId": "649def34f8be52c8b66281af98ae884c09aef38b",
  "externalIds": {
    "DOI": "10.18653/v1/N18-3011",
    "CorpusId": 49313245,
    "ArXiv": "1805.02262",
    "PubMed": "29355252",
    "MAG": "2800186467",
    "ACL": "N18-3011"
  },
  "title": "Paper Title Here"
}
```

================================================================================
SECTION 4: ACADEMIC GRAPH API ENDPOINTS
================================================================================

4.1 PAPER ENDPOINTS
-------------------

PAPER DETAILS
Endpoint: GET /graph/v1/paper/{paper_id}
Purpose: Get details about a single paper

Path Parameters:
- paper_id: S2PaperId, CorpusId, DOI, ArXivId, MAG, ACL, PMID, PMCID, or URL

Available Fields:
paperId, externalIds, url, title, abstract*, venue, publicationVenue,
year, referenceCount, citationCount, influentialCitationCount, isOpenAccess,
openAccessPdf, fieldsOfStudy, s2FieldsOfStudy, publicationTypes,
publicationDate, journal, citationStyles, authors, citations, references,
embedding, tldr

*Note: Springer abstracts NOT available due to licensing agreement

Example:
```python
import requests

response = requests.get(
    "https://api.semanticscholar.org/graph/v1/paper/10.1038/nrn3241",
    headers={"x-api-key": api_key},
    params={"fields": "title,authors,year,citationCount,abstract,externalIds"}
)
paper = response.json()
```

PAPER BATCH
Endpoint: POST /graph/v1/paper/batch
Purpose: Get details for up to 500 papers in one request

Request Body:
```json
{"ids": ["paper_id_1", "paper_id_2", ...]}
```

Example:
```python
response = requests.post(
    "https://api.semanticscholar.org/graph/v1/paper/batch",
    headers={"x-api-key": api_key},
    params={"fields": "title,year,citationCount"},
    json={"ids": [
        "649def34f8be52c8b66281af98ae884c09aef38b",
        "ARXIV:2106.15928",
        "PMID:19872477"
    ]}
)
```

PAPER RELEVANCE SEARCH
Endpoint: GET /graph/v1/paper/search
Purpose: Search papers by keyword with relevance ranking
Limit: Up to 1,000 results (offset + limit <= 1000)

Query Parameters:
- query (required): Search terms
- fields: Comma-separated field names
- offset: Starting position (default 0)
- limit: Results per page (max 100)
- year: Year or range (e.g., "2020-2023", "2023-")
- publicationTypes: Filter by type (JournalArticle, Conference, Review, etc.)
- openAccessPdf: Filter for open access papers
- minCitationCount: Minimum citations
- fieldsOfStudy: Filter by field (Medicine, Computer Science, etc.)
- venue: Filter by publication venue

Example:
```python
response = requests.get(
    "https://api.semanticscholar.org/graph/v1/paper/search",
    headers={"x-api-key": api_key},
    params={
        "query": "deep learning medical imaging",
        "fields": "title,authors,year,citationCount,publicationTypes",
        "limit": 50,
        "year": "2020-2024",
        "fieldsOfStudy": "Medicine,Computer Science"
    }
)
```

PAPER BULK SEARCH
Endpoint: GET /graph/v1/paper/search/bulk
Purpose: Retrieve up to 10 million papers (1000 per page) with sorting
Rate Limit: 1 RPS (authenticated)

Query Parameters:
- query (required): Search terms (supports operators: +, -, |, "", *, ~)
- token: Pagination token (returned in response for subsequent requests)
- fields: Comma-separated field names
- sort: <field>:<order> (paperId, publicationDate, citationCount + asc/desc)
- year, publicationTypes, openAccessPdf, minCitationCount, fieldsOfStudy, venue

Search Query Syntax:
- Exact phrase: "machine learning"
- Must include: +healthcare
- Must exclude: -survey
- OR operator: (deep learning) | (neural network)
- Wildcard: neuro*
- Fuzzy: bugs~3 (edit distance 3)
- Proximity: "blue lake"~3 (up to 3 words between)

Example:
```python
response = requests.get(
    "https://api.semanticscholar.org/graph/v1/paper/search/bulk",
    headers={"x-api-key": api_key},
    params={
        "query": '"transformer architecture" +attention',
        "fields": "title,year,citationCount",
        "year": "2017-",
        "sort": "citationCount:desc"
    }
)

# Pagination using token
data = response.json()
while "token" in data:
    response = requests.get(
        "https://api.semanticscholar.org/graph/v1/paper/search/bulk",
        headers={"x-api-key": api_key},
        params={"query": query, "token": data["token"]}
    )
    data = response.json()
```

PAPER TITLE SEARCH
Endpoint: GET /graph/v1/paper/search/match
Purpose: Find single paper with closest title match

PAPER AUTOCOMPLETE
Endpoint: GET /graph/v1/paper/autocomplete
Purpose: Get search suggestions for partial queries

PAPER CITATIONS
Endpoint: GET /graph/v1/paper/{paper_id}/citations
Purpose: Get papers that cite this paper

PAPER REFERENCES
Endpoint: GET /graph/v1/paper/{paper_id}/references
Purpose: Get papers referenced by this paper

PAPER AUTHORS
Endpoint: GET /graph/v1/paper/{paper_id}/authors
Purpose: Get authors of this paper

4.2 AUTHOR ENDPOINTS
--------------------

AUTHOR DETAILS
Endpoint: GET /graph/v1/author/{author_id}
Purpose: Get details about an author

Available Fields:
authorId, externalIds, url, name, affiliations, homepage, paperCount,
citationCount, hIndex, papers

AUTHOR BATCH
Endpoint: POST /graph/v1/author/batch
Purpose: Get details for multiple authors

AUTHOR SEARCH
Endpoint: GET /graph/v1/author/search
Purpose: Search for authors by name

AUTHOR PAPERS
Endpoint: GET /graph/v1/author/{author_id}/papers
Purpose: Get papers by an author

================================================================================
SECTION 5: RECOMMENDATIONS API
================================================================================

5.1 SINGLE PAPER RECOMMENDATIONS
--------------------------------
Endpoint: GET /recommendations/v1/papers/forpaper/{paper_id}
Purpose: Get papers similar to a given paper

Query Parameters:
- fields: Paper fields to return
- limit: Max recommendations (default 100, max 500)
- from: Paper pool ("recent" = last 60 days all fields, "all-cs" = all CS papers)

Example:
```python
response = requests.get(
    f"https://api.semanticscholar.org/recommendations/v1/papers/forpaper/{paper_id}",
    headers={"x-api-key": api_key},
    params={
        "fields": "title,authors,year,citationCount",
        "limit": 100,
        "from": "recent"
    }
)
```

5.2 MULTI-PAPER RECOMMENDATIONS
-------------------------------
Endpoint: POST /recommendations/v1/papers/
Purpose: Get recommendations based on positive and negative seed papers

Request Body:
```json
{
    "positivePaperIds": ["paper_id_1", "paper_id_2"],
    "negativePaperIds": ["paper_id_3"]
}
```

Example:
```python
response = requests.post(
    "https://api.semanticscholar.org/recommendations/v1/papers/",
    headers={"x-api-key": api_key},
    params={"fields": "title,citationCount,authors", "limit": 500},
    json={
        "positivePaperIds": [
            "649def34f8be52c8b66281af98ae884c09aef38b",
            "ARXIV:2106.15928"
        ],
        "negativePaperIds": [
            "PMID:19872477"
        ]
    }
)
```

================================================================================
SECTION 6: DATASETS API
================================================================================

6.1 AVAILABLE DATASETS
----------------------
Dataset Name        Description
--------------------------------------------------------------------------------
papers              Core paper metadata (title, authors, year, venue, etc.)
authors             Author information and statistics
abstracts           Paper abstracts (Springer excluded)
citations           Citation relationships between papers
paper-ids           Mapping of S2 IDs to external IDs
embeddings          SPECTER2 paper embeddings
tldrs               AI-generated paper summaries
s2orc               Full-text content (where available)
publication-venues  Venue/journal information

6.2 DATASET ENDPOINTS
---------------------

LIST RELEASES
Endpoint: GET /datasets/v1/release/
Purpose: Get all available release dates

GET LATEST RELEASE
Endpoint: GET /datasets/v1/release/latest
Purpose: Get info about the latest release

GET RELEASE DETAILS
Endpoint: GET /datasets/v1/release/{release_id}
Purpose: Get datasets available in a specific release
Note: release_id can be a date (YYYY-MM-DD) or "latest"

GET DATASET DOWNLOAD LINKS
Endpoint: GET /datasets/v1/release/{release_id}/dataset/{dataset_name}
Purpose: Get temporary download links for a dataset
Requires: API key authentication

Example:
```python
# Get latest release ID
release_response = requests.get(
    "https://api.semanticscholar.org/datasets/v1/release/latest",
    headers={"x-api-key": api_key}
)
release_id = release_response.json()["release_id"]

# Get download links for papers dataset
dataset_response = requests.get(
    f"https://api.semanticscholar.org/datasets/v1/release/{release_id}/dataset/papers",
    headers={"x-api-key": api_key}
)
download_links = dataset_response.json().get("files", [])
```

6.3 INCREMENTAL UPDATES
-----------------------
Endpoint: GET /datasets/v1/diffs/{start_release_id}/to/{end_release_id}/{dataset_name}
Purpose: Get changes between two releases (avoids full re-download)

Response contains:
- update_files: Records to insert/replace
- delete_files: Records to remove

Example:
```python
response = requests.get(
    f"https://api.semanticscholar.org/datasets/v1/diffs/2024-01-01/to/2024-01-15/papers",
    headers={"x-api-key": api_key}
)
diffs = response.json()["diffs"]
```

================================================================================
SECTION 7: PAPER FIELD REFERENCE
================================================================================

7.1 ALL AVAILABLE PAPER FIELDS
------------------------------

BASIC FIELDS (always available):
- paperId: Semantic Scholar unique identifier
- externalIds: Object containing DOI, ArXiv, PubMed, MAG, ACL, CorpusId
- url: Semantic Scholar paper page URL
- title: Paper title
- venue: Publication venue name
- publicationVenue: Detailed venue object
- year: Publication year
- referenceCount: Number of references
- citationCount: Number of citations
- influentialCitationCount: Number of influential citations
- isOpenAccess: Boolean for open access status
- openAccessPdf: Object with URL and status if available
- fieldsOfStudy: Array of field names (external source)
- s2FieldsOfStudy: Array of objects with category and source
- publicationTypes: Array (JournalArticle, Conference, Review, etc.)
- publicationDate: ISO date string
- journal: Journal information object

EXTENDED FIELDS (may increase response time):
- abstract: Paper abstract (NOTE: Springer abstracts unavailable)
- authors: Array of author objects
- citations: Array of citing paper objects
- references: Array of referenced paper objects
- embedding: SPECTER2 embedding vector
- tldr: AI-generated summary object
- citationStyles: Formatted citation strings

7.2 AUTHOR OBJECT FIELDS
------------------------
- authorId: Semantic Scholar author ID
- name: Author name
- externalIds: ORCID, DBLP identifiers
- url: Author page URL
- affiliations: Array of affiliation strings
- homepage: Personal homepage URL
- paperCount: Number of papers
- citationCount: Total citations
- hIndex: h-index metric

7.3 s2FieldsOfStudy VS fieldsOfStudy
------------------------------------
fieldsOfStudy: External source only, list of strings
s2FieldsOfStudy: Combined external + S2 classifier, list of objects:
```json
[
  {"category": "Computer Science", "source": "external"},
  {"category": "Computer Science", "source": "s2-fos-model"}
]
```

Note: s2FieldsOfStudy will replace fieldsOfStudy (deprecated)

================================================================================
SECTION 8: REQUIRED PACKAGES AND DEPENDENCIES
================================================================================

8.1 PYTHON REQUIREMENTS
-----------------------

CORE DEPENDENCIES:
```
requests>=2.28.0
python-dotenv>=1.0.0  # For API key management
```

RECOMMENDED ADDITIONS:
```
urllib3>=2.0.0        # For retry logic
aiohttp>=3.8.0        # For async requests
pandas>=2.0.0         # For data manipulation
```

8.2 INSTALLATION
----------------
```bash
pip install requests python-dotenv urllib3

# For the unofficial Python client library:
pip install semanticscholar
```

8.3 UNOFFICIAL PYTHON CLIENT
----------------------------
Package: semanticscholar
GitHub: https://github.com/danielnsilva/semanticscholar
Docs: https://semanticscholar.readthedocs.io/

Features:
- Simplified access to all three APIs
- Typed responses
- Automatic pagination handling
- Async support

Installation:
```bash
pip install semanticscholar
```

Usage:
```python
from semanticscholar import SemanticScholar

sch = SemanticScholar(api_key="your_key")

# Get paper by DOI
paper = sch.get_paper("10.1038/nrn3241")
print(paper.title)
print(paper.citationCount)

# Search papers
results = sch.search_paper("machine learning healthcare", limit=100)
for paper in results:
    print(paper.title)

# Get recommendations
recommendations = sch.get_recommended_papers(paper_id)
```

================================================================================
SECTION 9: BEST PRACTICES AND ERROR HANDLING
================================================================================

9.1 EXPONENTIAL BACKOFF (REQUIRED)
----------------------------------
Semantic Scholar REQUIRES exponential backoff for all API requests.

Recommended implementation:
```python
from requests import Session
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

http = Session()
http.mount('https://', HTTPAdapter(max_retries=Retry(
    total=6,
    backoff_factor=2.0,
    backoff_jitter=0.5,
    respect_retry_after_header=True,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods={"GET", "POST"}
)))

response = http.get(
    "https://api.semanticscholar.org/graph/v1/paper/search",
    headers={"x-api-key": api_key},
    params={"query": "machine learning"}
)
```

9.2 HTTP STATUS CODES
---------------------
200 OK: Request successful
400 Bad Request: Invalid parameters
403 Forbidden: Invalid or missing API key
404 Not Found: Resource doesn't exist
429 Too Many Requests: Rate limit exceeded (check Retry-After header)
500 Internal Server Error: Server-side issue
502/503/504: Temporary server issues (retry with backoff)

9.3 OPTIMIZATION TIPS
---------------------
1. BATCH REQUESTS: Use /paper/batch for multiple lookups (up to 500 IDs)
2. LIMIT FIELDS: Only request fields you need
3. USE BULK SEARCH: For large-scale retrieval (up to 10M papers)
4. DOWNLOAD DATASETS: For massive queries, download full datasets locally
5. REUSE CONNECTIONS: Use requests.Session() for connection pooling

9.4 API KEY MANAGEMENT
----------------------
```python
import os
from dotenv import load_dotenv

load_dotenv()  # Load from .env file
api_key = os.getenv("S2_API_KEY")

if not api_key:
    raise ValueError("S2_API_KEY environment variable not set")
```

.env file:
```
S2_API_KEY=your_api_key_here
```

================================================================================
SECTION 10: COMPLETE CODE EXAMPLES
================================================================================

10.1 SEARCH AND RETRIEVE PAPERS BY DOI/CrossRef
-----------------------------------------------
```python
import os
import requests
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv("S2_API_KEY")

def get_paper_by_doi(doi: str) -> dict:
    """Retrieve paper details using DOI (CrossRef compatible)."""
    response = requests.get(
        f"https://api.semanticscholar.org/graph/v1/paper/{doi}",
        headers={"x-api-key": API_KEY},
        params={
            "fields": "paperId,externalIds,title,authors,year,"
                      "citationCount,abstract,publicationTypes,"
                      "openAccessPdf,s2FieldsOfStudy"
        }
    )
    response.raise_for_status()
    return response.json()

def batch_lookup_by_ids(ids: list[str]) -> list[dict]:
    """Batch lookup papers by mixed ID types (DOI, PMID, arXiv, etc.)."""
    response = requests.post(
        "https://api.semanticscholar.org/graph/v1/paper/batch",
        headers={"x-api-key": API_KEY},
        params={"fields": "paperId,externalIds,title,year,citationCount"},
        json={"ids": ids}
    )
    response.raise_for_status()
    return response.json()

# Usage
paper = get_paper_by_doi("10.1038/nrn3241")
print(f"Title: {paper['title']}")
print(f"Citations: {paper['citationCount']}")
print(f"External IDs: {paper['externalIds']}")

# Batch lookup with mixed ID types
papers = batch_lookup_by_ids([
    "10.1038/nrn3241",      # DOI
    "PMID:19872477",        # PubMed
    "arXiv:2106.15928",     # arXiv
    "CorpusID:37220927"     # S2 Corpus ID
])
```

10.2 BULK SEARCH WITH PAGINATION
--------------------------------
```python
import os
import json
import requests
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

load_dotenv()
API_KEY = os.getenv("S2_API_KEY")

def search_papers_bulk(query: str, year: str = None, 
                       fields_of_study: str = None,
                       max_papers: int = 10000) -> list[dict]:
    """
    Bulk search for papers with automatic pagination.
    Returns up to max_papers results.
    """
    session = requests.Session()
    session.mount('https://', HTTPAdapter(max_retries=Retry(
        total=5, backoff_factor=2.0, status_forcelist=[429, 500, 502, 503, 504]
    )))
    
    params = {
        "query": query,
        "fields": "paperId,title,year,citationCount,authors,externalIds"
    }
    if year:
        params["year"] = year
    if fields_of_study:
        params["fieldsOfStudy"] = fields_of_study
    
    all_papers = []
    url = "https://api.semanticscholar.org/graph/v1/paper/search/bulk"
    
    while len(all_papers) < max_papers:
        response = session.get(
            url, headers={"x-api-key": API_KEY}, params=params
        )
        response.raise_for_status()
        data = response.json()
        
        papers = data.get("data", [])
        all_papers.extend(papers)
        
        if "token" not in data:
            break
        params["token"] = data["token"]
    
    return all_papers[:max_papers]

# Usage
papers = search_papers_bulk(
    query='"deep learning" +medical +imaging',
    year="2020-2024",
    fields_of_study="Medicine,Computer Science",
    max_papers=5000
)
print(f"Retrieved {len(papers)} papers")
```

10.3 GET PAPER RECOMMENDATIONS
------------------------------
```python
def get_recommendations(positive_ids: list[str], 
                        negative_ids: list[str] = None,
                        limit: int = 100) -> list[dict]:
    """
    Get paper recommendations based on positive/negative examples.
    IDs can be any supported format (DOI, PMID, arXiv, etc.)
    """
    response = requests.post(
        "https://api.semanticscholar.org/recommendations/v1/papers/",
        headers={"x-api-key": API_KEY},
        params={
            "fields": "paperId,title,year,citationCount,authors,externalIds",
            "limit": limit
        },
        json={
            "positivePaperIds": positive_ids,
            "negativePaperIds": negative_ids or []
        }
    )
    response.raise_for_status()
    return response.json().get("recommendedPapers", [])

# Usage
recommendations = get_recommendations(
    positive_ids=["10.1038/nature14539", "arXiv:1706.03762"],
    negative_ids=["10.1109/CVPR.2016.90"],
    limit=50
)
```

10.4 DOWNLOAD DATASET
---------------------
```python
def download_dataset(dataset_name: str, output_dir: str = "."):
    """Download a Semantic Scholar dataset."""
    import urllib.request
    import gzip
    import shutil
    
    # Get latest release
    release_resp = requests.get(
        "https://api.semanticscholar.org/datasets/v1/release/latest",
        headers={"x-api-key": API_KEY}
    )
    release_id = release_resp.json()["release_id"]
    
    # Get download links
    dataset_resp = requests.get(
        f"https://api.semanticscholar.org/datasets/v1/release/{release_id}/dataset/{dataset_name}",
        headers={"x-api-key": API_KEY}
    )
    files = dataset_resp.json().get("files", [])
    
    for i, file_info in enumerate(files):
        url = file_info["url"]
        filename = f"{output_dir}/{dataset_name}_{i}.jsonl.gz"
        print(f"Downloading {filename}...")
        urllib.request.urlretrieve(url, filename)

# Usage
download_dataset("papers", output_dir="./datasets")
```

================================================================================
SECTION 11: API ENDPOINT QUICK REFERENCE
================================================================================

PAPER SERVICES
--------------
GET  /graph/v1/paper/{paper_id}              Single paper details
POST /graph/v1/paper/batch                   Batch paper lookup (≤500)
GET  /graph/v1/paper/search                  Relevance search (≤1000)
GET  /graph/v1/paper/search/bulk             Bulk search (≤10M)
GET  /graph/v1/paper/search/match            Title match search
GET  /graph/v1/paper/autocomplete            Search autocomplete
GET  /graph/v1/paper/{paper_id}/authors      Paper's authors
GET  /graph/v1/paper/{paper_id}/citations    Papers citing this paper
GET  /graph/v1/paper/{paper_id}/references   Papers referenced

AUTHOR SERVICES
---------------
GET  /graph/v1/author/{author_id}            Author details
POST /graph/v1/author/batch                  Batch author lookup
GET  /graph/v1/author/search                 Author search
GET  /graph/v1/author/{author_id}/papers     Author's papers

RECOMMENDATIONS SERVICES
------------------------
GET  /recommendations/v1/papers/forpaper/{paper_id}    Single-seed recommendations
POST /recommendations/v1/papers/                       Multi-seed recommendations

DATASETS SERVICES
-----------------
GET  /datasets/v1/release/                   List all releases
GET  /datasets/v1/release/latest             Latest release info
GET  /datasets/v1/release/{release_id}       Release details
GET  /datasets/v1/release/{release_id}/dataset/{dataset_name}  Download links
GET  /datasets/v1/diffs/{start}/to/{end}/{dataset_name}        Incremental updates

================================================================================
SECTION 12: IMPORTANT NOTES AND LIMITATIONS
================================================================================

12.1 KNOWN LIMITATIONS
----------------------
- Springer abstracts NOT available (licensing restriction)
- Free email domains not accepted for new API keys
- Third-party app keys no longer issued
- 60-day inactive keys auto-pruned
- Rate limits are strictly enforced

12.2 DATA QUALITY NOTES
-----------------------
- Missing/ambiguous/incorrect data may exist for any field
- Report errors via: https://www.semanticscholar.org/faq#authorship-error
- Aliases field deprecated (May 2024) to prevent deadnaming

12.3 ATTRIBUTION REQUIREMENT
----------------------------
When displaying Semantic Scholar data publicly, include:
"Data source: Semantic Scholar API https://api.semanticscholar.org"

12.4 SUPPORT AND RESOURCES
--------------------------
- API Status: https://status.api.semanticscholar.org/
- API Documentation: https://api.semanticscholar.org/api-docs/
- Community Slack: https://join.slack.com/t/semanticschol-xyj3882/shared
- Feedback: feedback@semanticscholar.org
- GitHub Examples: https://github.com/allenai/s2-folks

================================================================================
END OF DOCUMENTATION
================================================================================
